# ================================================
# üîÆ PREDICCI√ìN DEL PR√ìXIMO MICROCICLO (FINAL)
# ================================================
import os
import sqlite3
import pandas as pd
import joblib

# ================================================
# üìÅ Configuraci√≥n de rutas
# ================================================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
DB_PATH = r"C:/Users/Nico/Desktop/DATA SCIENCE/PP- VOLUNTAREADO/chivas-ml/data/external/chivas_dw.sqlite"
REGISTRY_DIR = os.path.join(BASE_DIR, "ml", "registry")

# ================================================
# üß© Carga de modelos
# ================================================
def load_model(path_folder, model_name, scaler_name):
    model = joblib.load(os.path.join(path_folder, model_name))
    scaler = joblib.load(os.path.join(path_folder, scaler_name))
    return model, scaler


# ================================================
# üîç √öltimo microciclo completo
# ================================================
def obtener_microciclo_completo(conn):
    query = """
        SELECT Microciclo_Num, COUNT(DISTINCT Fecha) AS dias
        FROM BI_Cargas_Diarias
        GROUP BY Microciclo_Num
        ORDER BY Microciclo_Num DESC
    """
    df = pd.read_sql(query, conn)
    completos = df[df["dias"] >= 6]
    return completos["Microciclo_Num"].max()


# ================================================
# üß± Preparar datos de entrada
# ================================================
def preparar_datos(conn):
    # 1Ô∏è‚É£ Detectar √∫ltimo microciclo completo
    microciclo_actual = obtener_microciclo_completo(conn)
    microciclo_next = microciclo_actual + 1
    print(f"üìÜ √öltimo microciclo completo detectado: {microciclo_actual}")

    # 2Ô∏è‚É£ Cargar vista base
    query = f"""
        SELECT *
        FROM vw_predicciones_diarias_extendida
        WHERE Microciclo_actual = {microciclo_actual}
    """
    df = pd.read_sql(query, conn)
    print(f"[OK] Datos cargados desde vw_predicciones_diarias_extendida ({len(df)} filas).")

    # 3Ô∏è‚É£ Cargar planificaci√≥n del microciclo siguiente
    query_plan = f"""
        SELECT Fecha, Tipo_Dia, Intensidad, Microciclo_Num
        FROM DB_MicrociclosExcel
        WHERE Microciclo_Num = {microciclo_next}
        ORDER BY Fecha
    """
    df_plan = pd.read_sql(query_plan, conn)
    df_plan["Fecha"] = pd.to_datetime(df_plan["Fecha"]).dt.normalize()
    if df_plan.empty:
        raise ValueError(f"‚ö†Ô∏è No hay planificaci√≥n para el microciclo {microciclo_next}")

    # 4Ô∏è‚É£ Mapear tipo_dia_next con la misma codificaci√≥n usada en entrenamiento
    def map_tipo_dia_next(row):
        if row["Tipo_Dia"].upper() == "DESCANSO":
            return 0
        elif row["Tipo_Dia"].upper() == "ENTRENO":
            if row["Intensidad"] <= -2:
                return 1   # muy suave
            elif row["Intensidad"] == -1:
                return 2   # medio-bajo
            elif row["Intensidad"] == 1:
                return 3   # medio-alto
            elif row["Intensidad"] >= 2:
                return 4   # alta carga
            else:
                return 2
        elif row["Tipo_Dia"].upper() == "PARTIDO":
            return 0
        else:
            return 0

    df_plan["tipo_dia_next"] = df_plan.apply(map_tipo_dia_next, axis=1).astype(float)

    # 5Ô∏è‚É£ Contexto fisiol√≥gico del jugador
    df["Posicion"] = df["Posicion"].fillna("Desconocido")
    df["Linea"] = df["Linea"].fillna("Desconocido")

    player_mean = df.groupby("id_jugador").agg({
        "Distancia_total": "mean",
        "Player_Load": "mean",
        "Acc_3": "mean",
        "Dec_3": "mean"
    }).rename(columns={
        "Distancia_total": "jugador_mean_dist",
        "Player_Load": "jugador_mean_load",
        "Acc_3": "jugador_mean_acc",
        "Dec_3": "jugador_mean_dec"
    }).reset_index()

    df = df.merge(player_mean, on="id_jugador", how="left")
    df = pd.get_dummies(df, columns=["Posicion", "Linea"], prefix=["Pos", "Lin"])

        # üí° Asegurar todas las columnas dummy que exist√≠an en el entrenamiento
    columnas_esperadas = [
        "Pos_Defensor", "Pos_Delantero", "Pos_Mediocampista",
        "Lin_Defensa Central", "Lin_Defensa Lateral", "Lin_Delantera",
        "Lin_Extremo", "Lin_Medio Defensivo", "Lin_Medio Ofensivo"
    ]

    for col in columnas_esperadas:
        if col not in df.columns:
            df[col] = 0.0  # agregamos columna dummy faltante

    print("‚úÖ Columnas dummy normalizadas (todas las posiciones y l√≠neas presentes).")


    # üßπ Asegurar formato de fecha y eliminar duplicados
    if "Fecha" not in df.columns:
        for col in ["Fecha_x", "Fecha_y"]:
            if col in df.columns:
                df.rename(columns={col: "Fecha"}, inplace=True)
    df["Fecha"] = pd.to_datetime(df["Fecha"]).dt.normalize()

    # üß© Eliminar duplicados de la vista base (una fila por jugador y fecha)
    numeric_cols = df.select_dtypes(include=["number"]).columns
    df = df.groupby(["id_jugador", "Fecha"], as_index=False)[numeric_cols].mean(numeric_only=True)
    print(f"üß© Agrupado df base: {len(df)} filas √∫nicas (1 por jugador y d√≠a).")

    # 6Ô∏è‚É£ Crear estructura jugador √ó fecha del microciclo siguiente
    jugadores = df["id_jugador"].unique()
    fechas_plan = df_plan["Fecha"].unique()
    grid = pd.MultiIndex.from_product([jugadores, fechas_plan], names=["id_jugador", "Fecha"]).to_frame(index=False)

    # 7Ô∏è‚É£ Combinar planificaci√≥n e info de jugadores
    df_next = grid.merge(df_plan, on="Fecha", how="left")
    df_next = df_next.merge(df.drop(columns=["Fecha"]), on="id_jugador", how="left")

    # üßπ Unificar columnas duplicadas (_x / _y)
    for col in ["Tipo_Dia", "tipo_dia_next"]:
        cols_posibles = [c for c in df_next.columns if c.startswith(col)]
        if len(cols_posibles) > 1:
            df_next[col] = df_next[cols_posibles].bfill(axis=1).iloc[:, 0]
            df_next.drop(columns=[c for c in cols_posibles if c != col], inplace=True)
        elif len(cols_posibles) == 1:
            df_next.rename(columns={cols_posibles[0]: col}, inplace=True)
        else:
            df_next[col] = None

    # 8Ô∏è‚É£ Asignar microciclos
    df_next["microciclo_actual"] = microciclo_actual
    df_next["microciclo_next"] = microciclo_next

    # 9Ô∏è‚É£ Aplicar factor de intensidad diaria a features fisiol√≥gicos
    if "tipo_dia_next" in df_next.columns:
        intensidad_factor = df_next["tipo_dia_next"]
        for col in [
            "CT_total_actual", "CE_total_actual", "CS_total_actual", "CR_total_actual",
            "jugador_mean_dist", "jugador_mean_load", "jugador_mean_acc", "jugador_mean_dec"
        ]:
            if col in df_next.columns:
                df_next[col] = df_next[col] * (1 + 0.1 * intensidad_factor)
        print("üß† Intensidad diaria aplicada a features de entrada.")
    else:
        print("‚ö†Ô∏è No se aplic√≥ ajuste de intensidad (columna tipo_dia_next ausente).")

    # üîπ Asegurar una sola fila por jugador y fecha (por si se duplica en merges)
    df_next = df_next.groupby(["id_jugador", "Fecha"], as_index=False).first()

    # 10Ô∏è‚É£ Mostrar resumen de columnas clave
    print(f"Columnas finales disponibles: {list(df_next.columns)}")
    print(f"üìÜ Fechas √∫nicas detectadas: {df_next['Fecha'].nunique()}")
    print(df_next[["Fecha", "Tipo_Dia", "tipo_dia_next"]].drop_duplicates().sort_values("Fecha").head(10))
    print("‚úÖ Datos de entrada listos para el pipeline de predicci√≥n.")

    return df_next, microciclo_actual


# ================================================
# üßÆ Pipeline de predicci√≥n jer√°rquica
# ================================================
def predict_pipeline(df):
    print("üöÄ Iniciando flujo de predicci√≥n jer√°rquica...\n")
    fecha_original = df["Fecha"].copy()  # üí° guardamos la columna para restaurarla despu√©s

    # 1Ô∏è‚É£ Predicci√≥n tipo de semana
    folder = "modelo_clas_carga_semanal"
    model, scaler = load_model(
        os.path.join(REGISTRY_DIR, folder),
        "model_weektype_rf.pkl",
        "scaler_weektype.pkl"
    )
    FEATURES_SEMANA = [
        'CT_total_actual', 'CE_total_actual', 'CS_total_actual', 'CR_total_actual',
        'entrenos_total_next', 'descansos_total_next', 'partidos_total_next',
        'descansos_pre_partido_next', 'entrenos_pre_partido_next', 'entrenos_post_partido_next'
    ]
    X_semana = df[FEATURES_SEMANA]
    df["tipo_semana_pred"] = model.predict(scaler.transform(X_semana))
    print("‚úÖ Tipo de semana predicha")

    # üîÑ Compatibilidad con entrenamiento
    df["tipo_semana_next"] = df["tipo_semana_pred"]

    # 2Ô∏è‚É£ Predicci√≥n Distancia total
    folder = "modelo_clas_distancia_total"
    model, scaler = load_model(
        os.path.join(REGISTRY_DIR, folder),
        "model_carga_diaria_rf_tendencias.pkl",
        "scaler_carga_diaria.pkl"
    )
    FEATURES_DIST = [
        'tipo_semana_next', 'tipo_dia_next',
        'CT_total_actual', 'CE_total_actual', 'CS_total_actual', 'CR_total_actual',
        'riesgo_suavizado_3d_actual',
        'entrenos_total_next', 'descansos_total_next', 'partidos_total_next',
        'entrenos_pre_partido_next', 'entrenos_post_partido_next',
        'jugador_mean_dist', 'jugador_mean_load', 'jugador_mean_acc', 'jugador_mean_dec'
    ] + [c for c in df.columns if c.startswith('Pos_') or c.startswith('Lin_')]

    X_dist = df[[c for c in FEATURES_DIST if c in df.columns]].copy()
    if 'tipo_semana_pred' in X_dist.columns:
        X_dist = X_dist.drop(columns=['tipo_semana_pred'])

    # üîß Compatibilidad total con el scaler
    expected_cols = list(scaler.feature_names_in_)
    for c in expected_cols:
        if c not in X_dist.columns:
            X_dist[c] = 0.0
    X_dist = X_dist[expected_cols]

    print(f"‚úÖ Columnas ajustadas al scaler ({len(expected_cols)} features).")

    df["Distancia_total_pred"] = model.predict(scaler.transform(X_dist))
    print("‚úÖ Distancia total predicha")

    # 3Ô∏è‚É£ Predicci√≥n Carga Explosiva y Sostenida
    for name, folder, m, s in [
        ("CE", "modelo_clas_CE", "model_rf_CE_tendencias.pkl", "scaler_CE.pkl"),
        ("CS", "modelo_clas_CS", "model_rf_CS_tendencias.pkl", "scaler_CS.pkl")
    ]:
        model, scaler = load_model(os.path.join(REGISTRY_DIR, folder), m, s)

        df["tipo_semana_next"] = df["tipo_semana_pred"]
        df["Distancia_total"] = df["Distancia_total_pred"]

        FEATURES_CARGAS = [
            'tipo_semana_next', 'tipo_dia_next', 'Distancia_total',
            'CT_total_actual', 'CE_total_actual', 'CS_total_actual', 'CR_total_actual',
            'riesgo_suavizado_3d_actual',
            'entrenos_total_next', 'descansos_total_next', 'partidos_total_next',
            'entrenos_pre_partido_next', 'entrenos_post_partido_next',
            'jugador_mean_dist', 'jugador_mean_load', 'jugador_mean_acc', 'jugador_mean_dec'
        ] + [c for c in df.columns if c.startswith('Pos_') or c.startswith('Lin_')]

        X_cargas = df[[c for c in FEATURES_CARGAS if c in df.columns]].copy()
        for col in ['tipo_semana_pred', 'Distancia_total_pred']:
            if col in X_cargas.columns:
                X_cargas = X_cargas.drop(columns=[col])

        # üîß Ajustar columnas al scaler dentro del bucle
        expected_cols = list(scaler.feature_names_in_)
        for c in expected_cols:
            if c not in X_cargas.columns:
                X_cargas[c] = 0.0
        X_cargas = X_cargas[expected_cols]

        df[f"{name}_pred"] = model.predict(scaler.transform(X_cargas))
        print(f"‚úÖ {name} predicho con {len(expected_cols)} features validados.")

    print("‚úÖ Cargas CE y CS predichas")

    # 4Ô∏è‚É£ Predicci√≥n de m√©tricas micro (Acc, Dec, HMLD, HSR, Sprint)
    print("üîÑ Iniciando predicci√≥n de m√©tricas micro...")
    df["tipo_semana_next"] = df["tipo_semana_pred"]
    df["Distancia_total"] = df["Distancia_total_pred"]
    df["Carga_Explosiva"] = df["CE_pred"]
    df["Carga_Sostenida"] = df["CS_pred"]

    micro_models = {
        "Acc_3": ("modelo_clas_Acc_3", "model_rf_acc_3_tendencias.pkl", "scaler_acc_3.pkl"),
        "Dec_3": ("modelo_clas_Dec_3", "model_rf_dec_3_tendencias.pkl", "scaler_dec_3.pkl"),
        "HMLD_m": ("modelo_clas_hmld", "model_rf_hmld_m_tendencias.pkl", "scaler_hmld_m.pkl"),
        "HSR_abs_m": ("modelo_clas_hsr", "model_rf_hsr_abs_m_tendencias.pkl", "scaler_hsr_abs_m.pkl"),
        "Sprint_vel_max_kmh": ("modelo_clas_Sprints_vel_max_kmh", "model_rf_sprints_vel_tendencias.pkl", "scaler_sprints_vel.pkl")
    }

    for col, (folder, model_name, scaler_name) in micro_models.items():
        model, scaler = load_model(os.path.join(REGISTRY_DIR, folder), model_name, scaler_name)

        FEATURES_MICRO = [
            'tipo_semana_next', 'tipo_dia_next', 'Carga_Explosiva', 'Carga_Sostenida', 'Distancia_total',
            'CT_total_actual', 'CE_total_actual', 'CS_total_actual', 'CR_total_actual',
            'riesgo_suavizado_3d_actual',
            'entrenos_total_next', 'descansos_total_next', 'partidos_total_next',
            'entrenos_pre_partido_next', 'entrenos_post_partido_next',
            'jugador_mean_dist', 'jugador_mean_load', 'jugador_mean_acc', 'jugador_mean_dec'
        ] + [c for c in df.columns if c.startswith('Pos_') or c.startswith('Lin_')]

        X_micro = df[[c for c in FEATURES_MICRO if c in df.columns]].copy()
        for col_drop in ['tipo_semana_pred', 'Distancia_total_pred', 'CE_pred', 'CS_pred']:
            if col_drop in X_micro.columns:
                X_micro = X_micro.drop(columns=[col_drop])

        # üîß Ajustar columnas al scaler dentro del bucle
        expected_cols = list(scaler.feature_names_in_)
        for c in expected_cols:
            if c not in X_micro.columns:
                X_micro[c] = 0.0
        X_micro = X_micro[expected_cols]

        df[f"{col}_pred"] = model.predict(scaler.transform(X_micro))
        print(f"‚úÖ {col} predicho correctamente ({len(expected_cols)} features validados).")

    print("‚úÖ M√©tricas micro predichas correctamente")

    # üíæ Restaurar columna de fecha para an√°lisis temporal
    if "Fecha" not in df.columns:
        df["Fecha"] = fecha_original
    print("üìÖ Columna Fecha preservada para visualizaci√≥n en Power BI.")

    return df

# ================================================
# üí§ Agregar d√≠as de descanso (relleno con 0)
# ================================================
def agregar_dias_descanso(df_result, conn, microciclo_predicho):
    print("üß© Integrando d√≠as de descanso al resultado final...")
    fecha_original = df_result["Fecha"].copy()  # üí° guardamos la columna para restaurarla despu√©s


    # 1Ô∏è‚É£ Asegurar que exista la columna Fecha en df_result
    if "Fecha_x" in df_result.columns:
        df_result.rename(columns={"Fecha_x": "Fecha"}, inplace=True)
    if "Fecha_y" in df_result.columns:
        df_result.drop(columns=["Fecha_y"], inplace=True, errors="ignore")

    if "Fecha" not in df_result.columns:
        raise ValueError("‚ùå df_result no contiene columna Fecha.")

    df_result["Fecha"] = pd.to_datetime(df_result["Fecha"]).dt.normalize()

    # 2Ô∏è‚É£ Cargar planificaci√≥n semanal (DB_MicrociclosExcel)
    df_plan = pd.read_sql(f"""
        SELECT Fecha, Tipo_Dia, Intensidad
        FROM DB_MicrociclosExcel
        WHERE Microciclo_Num = {microciclo_predicho}
    """, conn)
    df_plan["Fecha"] = pd.to_datetime(df_plan["Fecha"]).dt.normalize()

    # 3Ô∏è‚É£ Generar estructura base: jugador √ó fecha_plan
    jugadores = df_result["id_jugador"].unique()
    fechas_plan = df_plan["Fecha"].unique()
    df_grid = pd.DataFrame(
        [(j, f) for j in jugadores for f in fechas_plan],
        columns=["id_jugador", "Fecha"]
    )

    # 4Ô∏è‚É£ Unir planificaci√≥n (Tipo_Dia, Intensidad)
    df_final = df_grid.merge(df_plan, on="Fecha", how="left")

    # 5Ô∏è‚É£ Unir predicciones por jugador y fecha (‚ùóla correcci√≥n clave)
    df_result["Fecha"] = pd.to_datetime(df_result["Fecha"]).dt.normalize()
    df_final = df_final.merge(
        df_result,
        on=["id_jugador", "Fecha"],
        how="left",
        suffixes=("", "_pred")
    )

    # 6Ô∏è‚É£ Rellenar d√≠as sin datos con 0 (descanso o partido)
    metricas = [
        "Distancia_total_pred", "CE_pred", "CS_pred",
        "Acc_3_pred", "Dec_3_pred", "HMLD_m_pred",
        "HSR_abs_m_pred", "Sprint_vel_max_kmh_pred"
    ]
    for m in metricas:
        if m in df_final.columns:
            mask = df_final["Tipo_Dia"].isin(["DESCANSO", "PARTIDO"])
            df_final.loc[mask, m] = 0
            df_final[m] = df_final[m].fillna(0)

    # 7Ô∏è‚É£ Mantener contexto y limpiar duplicados
    df_final["microciclo_next"] = microciclo_predicho
    if "tipo_semana_pred" in df_result.columns:
        df_final["tipo_semana_pred"] = df_result["tipo_semana_pred"].iloc[0]

    # 8Ô∏è‚É£ Limpieza final: eliminar columnas duplicadas o *_pred innecesarias
    drop_cols = [c for c in df_final.columns if c.endswith("_pred") and c not in metricas]
    df_final.drop(columns=drop_cols, inplace=True, errors="ignore")

    df_final = df_final.loc[:, ~df_final.columns.duplicated()]

    print(f"‚úÖ D√≠as de descanso integrados correctamente ({len(df_final)} filas, {len(df_final['Fecha'].unique())} fechas √∫nicas).")
    
    # üíæ Restaurar columna de fecha para an√°lisis temporal
    if "Fecha" not in df_final.columns:
        df_final["Fecha"] = fecha_original

    # üßπ Normalizamos formato de fecha (sin hora)
    df_final["Fecha"] = pd.to_datetime(df_final["Fecha"]).dt.date
    print("üìÖ Columna Fecha normalizada (sin horas).")

    print("üìÖ Columna Fecha preservada para visualizaci√≥n en Power BI.")
    
    return df_final




# ================================================
# üß© Ejecuci√≥n principal (llamada desde pipeline)
# ================================================
def ejecutar_prediccion_microciclo():
    conn = sqlite3.connect(DB_PATH)
    df_input, microciclo_actual = preparar_datos(conn)
    print(f"üéØ Prediciendo el microciclo {microciclo_actual + 1}...\n")
    print(df_input)

    print("\nüß© Diagn√≥stico de duplicaci√≥n en df_input:")
    duplicados = df_input.groupby(["id_jugador", "Fecha"]).size().reset_index(name="repeticiones")
    print(duplicados[duplicados["repeticiones"] > 1].head(10))
    print(f"Total de combinaciones duplicadas: {len(duplicados[duplicados['repeticiones'] > 1])}")
    print(f"Columnas actuales: {list(df_input.columns)}")


    df_result = predict_pipeline(df_input)

    print(df_result.columns)
    print("\nüîç Chequeo de variaci√≥n real entre d√≠as (post-predict):")
    print(df_result.groupby('tipo_dia_next')[['Distancia_total_pred', 'CE_pred', 'CS_pred']].mean().round(2))

    df_final = agregar_dias_descanso(df_result, conn, microciclo_actual + 1)
    print(df_result.columns)
    print(df_final["Fecha"])
    # ======================================================
    # üßπ DEPURACI√ìN FINAL DE COLUMNAS (para vista Power BI)
    # ======================================================
    columnas_finales = [
        # Identificaci√≥n y contexto
        "id_jugador", "Fecha", "microciclo_actual", "microciclo_next",

        # Planificaci√≥n semanal
        "Tipo_Dia", "Intensidad", "entrenos_total_next", "descansos_total_next",
        "partidos_total_next", "descansos_pre_partido_next",
        "entrenos_pre_partido_next", "entrenos_post_partido_next",
        "tipo_semana_pred",

        # Predicciones principales
        "Distancia_total_pred", "CE_pred", "CS_pred", "Acc_3_pred",
        "Dec_3_pred", "HMLD_m_pred", "HSR_abs_m_pred", "Sprint_vel_max_kmh_pred"
    ]

    # Verificar qu√© columnas existen realmente en df_final
    columnas_presentes = [c for c in columnas_finales if c in df_final.columns]
    df_final = df_final[columnas_presentes].copy()

    # Eliminar duplicadas o antiguas
    df_final = df_final.loc[:, ~df_final.columns.duplicated()]

    # Renombrar columnas para consistencia
    df_final.rename(columns={
        "Fecha_x": "Fecha",
        "tipo_semana_pred": "Tipo_Semana_Pred"
    }, inplace=True)

    print(f"üßæ Tabla final depurada con {len(df_final.columns)} columnas listas para guardar.")

    df_final.to_sql("ML_Predicciones_Semanales", conn, if_exists="replace", index=False)
    conn.close()
    print("üìä Resultados guardados correctamente (incluyendo descansos)")

    return df_final
